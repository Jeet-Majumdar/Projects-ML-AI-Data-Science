{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFWbEb6uGbN-"
      },
      "source": [
        "# Predicting the next word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOwsuGQQY9OL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTxqlHqKHzhr"
      },
      "source": [
        "We will be using the [Shakespeare Sonnets Dataset](https://www.opensourceshakespeare.org/views/sonnets/sonnet_view.php?range=viewrange&sonnetrange1=1&sonnetrange2=154), which contains more than 2000 lines of text extracted from Shakespeare's sonnets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZ4qOUzujMP6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65ca3ddb-5102-4d83-9ebc-f018e05aaa01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=108jAePKK4R3BVYBbYJZ32JWUwxeMg20K\n",
            "To: /content/sonnets.txt\n",
            "100% 93.6k/93.6k [00:00<00:00, 78.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "# sonnets.txt\n",
        "!gdown --id 108jAePKK4R3BVYBbYJZ32JWUwxeMg20K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pfd-nYKij5yY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e491301b-54d8-4c0e-fde9-f43638b390ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2159 lines of sonnets\n",
            "\n",
            "The first 5 lines look like this:\n",
            "\n",
            "from fairest creatures we desire increase,\n",
            "that thereby beauty's rose might never die,\n",
            "but as the riper should by time decease,\n",
            "his tender heir might bear his memory:\n",
            "but thou, contracted to thine own bright eyes,\n"
          ]
        }
      ],
      "source": [
        "# Define path for file with sonnets\n",
        "SONNETS_FILE = './sonnets.txt'\n",
        "\n",
        "# Read the data\n",
        "with open('./sonnets.txt') as f:\n",
        "    data = f.read()\n",
        "\n",
        "# Convert to lower case and save as a list\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "print(f\"There are {len(corpus)} lines of sonnets\\n\")\n",
        "print(f\"The first 5 lines look like this:\\n\")\n",
        "for i in range(5):\n",
        "  print(corpus[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imB15zrSNhA1"
      },
      "source": [
        "## Tokenizing the text\n",
        "\n",
        "Now fit the Tokenizer to the corpus and save the total number of words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAhM_qAZk0o5"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77-0sA46OETa"
      },
      "source": [
        "When converting the text into sequences you can use the `texts_to_sequences` method as you have done throughout this course.\n",
        "\n",
        "The first example of the corpus is a string and looks like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqhPxdeXlfjh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8020e9da-7612-4b4e-c540-257d40af99b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from fairest creatures we desire increase,'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "corpus[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFMP4z11O3os"
      },
      "source": [
        "If you pass this text directly into the `texts_to_sequences` method you will get an unexpected result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMSEhmbzNZCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "883fe5fc-4e22-4eeb-ff8d-e42fe2712772"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[],\n",
              " [],\n",
              " [58],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [17],\n",
              " [6],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [17],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [6],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [6],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [17],\n",
              " [],\n",
              " [],\n",
              " []]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "tokenizer.texts_to_sequences(corpus[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPZmZtpEPEeI"
      },
      "source": [
        "This happened because `texts_to_sequences` expects a list and we are providing a string. However a string is still and `iterable` in Python so you will get the word index of every character in the string.\n",
        "\n",
        "Instead we need to place the example whithin a list before passing it to the method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qmgo-vXhk4nd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6844346e-3568-499b-ca59-f781617454ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[34, 417, 877, 166, 213, 517]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "tokenizer.texts_to_sequences([corpus[0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DU7wK-eQ5dc"
      },
      "source": [
        "Notice that you received the sequence wrapped inside a list so in order to get only the desired sequence you need to explicitly get the first item in the list like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpTy8WmIQ57P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14d1e134-bbfc-49d8-f5c4-34e148e0c0c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[34, 417, 877, 166, 213, 517]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "tokenizer.texts_to_sequences([corpus[0]])[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oqy9KjXRJ9A"
      },
      "source": [
        "## Generating n_grams\n",
        "\n",
        "Now complete the `n_gram_seqs` function below. This function receives the fitted tokenizer and the corpus (which is a list of strings) and should return a list containing the `n_gram` sequences for each line in the corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iy4baJMDl6kj"
      },
      "outputs": [],
      "source": [
        "def n_gram_seqs(corpus, tokenizer):\n",
        "\tinput_sequences = []\n",
        "\n",
        "\tseq = tokenizer.texts_to_sequences(corpus)\n",
        "\n",
        "\tfor line in seq:\n",
        "\t\tn_words = len(line)\n",
        "\t\tfor i in range(2, n_words+1):\n",
        "\t\t\tinput_sequences.append(line[:i])\n",
        "\n",
        " return input_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlKqW2pfM7G3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3448a23-7641-446f-84af-02b59ce25c7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_gram sequences for first example look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[34, 417],\n",
              " [34, 417, 877],\n",
              " [34, 417, 877, 166],\n",
              " [34, 417, 877, 166, 213],\n",
              " [34, 417, 877, 166, 213, 517]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Testing function with one example\n",
        "first_example_sequence = n_gram_seqs([corpus[0]], tokenizer)\n",
        "\n",
        "print(\"n_gram sequences for first example look like this:\\n\")\n",
        "first_example_sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HL8Ug6UU0Jt"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "```\n",
        "n_gram sequences for first example look like this:\n",
        "\n",
        "[[34, 417],\n",
        " [34, 417, 877],\n",
        " [34, 417, 877, 166],\n",
        " [34, 417, 877, 166, 213],\n",
        " [34, 417, 877, 166, 213, 517]]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtPpCcBjNc4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "899f927c-6a20-4a3d-d215-611fa23c1789"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_gram sequences for next 3 examples look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[8, 878],\n",
              " [8, 878, 134],\n",
              " [8, 878, 134, 351],\n",
              " [8, 878, 134, 351, 102],\n",
              " [8, 878, 134, 351, 102, 156],\n",
              " [8, 878, 134, 351, 102, 156, 199],\n",
              " [16, 22],\n",
              " [16, 22, 2],\n",
              " [16, 22, 2, 879],\n",
              " [16, 22, 2, 879, 61],\n",
              " [16, 22, 2, 879, 61, 30],\n",
              " [16, 22, 2, 879, 61, 30, 48],\n",
              " [16, 22, 2, 879, 61, 30, 48, 634],\n",
              " [25, 311],\n",
              " [25, 311, 635],\n",
              " [25, 311, 635, 102],\n",
              " [25, 311, 635, 102, 200],\n",
              " [25, 311, 635, 102, 200, 25],\n",
              " [25, 311, 635, 102, 200, 25, 278]]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Testing function with a bigger corpus\n",
        "next_3_examples_sequence = n_gram_seqs(corpus[1:4], tokenizer)\n",
        "\n",
        "print(\"n_gram sequences for next 3 examples look like this:\\n\")\n",
        "next_3_examples_sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIzecMczU9UB"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "```\n",
        "n_gram sequences for next 3 examples look like this:\n",
        "\n",
        "[[8, 878],\n",
        " [8, 878, 134],\n",
        " [8, 878, 134, 351],\n",
        " [8, 878, 134, 351, 102],\n",
        " [8, 878, 134, 351, 102, 156],\n",
        " [8, 878, 134, 351, 102, 156, 199],\n",
        " [16, 22],\n",
        " [16, 22, 2],\n",
        " [16, 22, 2, 879],\n",
        " [16, 22, 2, 879, 61],\n",
        " [16, 22, 2, 879, 61, 30],\n",
        " [16, 22, 2, 879, 61, 30, 48],\n",
        " [16, 22, 2, 879, 61, 30, 48, 634],\n",
        " [25, 311],\n",
        " [25, 311, 635],\n",
        " [25, 311, 635, 102],\n",
        " [25, 311, 635, 102, 200],\n",
        " [25, 311, 635, 102, 200, 25],\n",
        " [25, 311, 635, 102, 200, 25, 278]]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx3V_RjFWQSu"
      },
      "source": [
        "Apply the `n_gram_seqs` transformation to the whole corpus and save the maximum sequence length to use it later:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laMwiRUpmuSd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abfd043b-b6a1-428e-e26a-ba5c1bdbd4cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_grams of input_sequences have length: 15462\n",
            "maximum length of sequences is: 11\n"
          ]
        }
      ],
      "source": [
        "# Applying the n_gram_seqs transformation to the whole corpus\n",
        "input_sequences = n_gram_seqs(corpus, tokenizer)\n",
        "\n",
        "# Saving max length\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "print(f\"n_grams of input_sequences have length: {len(input_sequences)}\")\n",
        "print(f\"maximum length of sequences is: {max_sequence_len}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OciMdmEdE9L"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "```\n",
        "n_grams of input_sequences have length: 15462\n",
        "maximum length of sequences is: 11\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHY7HroqWq12"
      },
      "source": [
        "## Add padding to the sequences\n",
        "\n",
        "Now code the `pad_seqs` function which will pad any given sequences to the desired maximum length. This function receives a list of sequences and should return a numpy array with the padded sequences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "WW1-qAZaWOhC"
      },
      "outputs": [],
      "source": [
        "def pad_seqs(input_sequences, maxlen):\n",
        "    padded_sequences = pad_sequences(input_sequences, maxlen=maxlen, padding='pre')\n",
        "    return padded_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqVQ0pb3YHLr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9e0f6a5-3c2f-49b3-8ec1-f764ca45282c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,  34, 417],\n",
              "       [  0,   0,  34, 417, 877],\n",
              "       [  0,  34, 417, 877, 166],\n",
              "       [ 34, 417, 877, 166, 213],\n",
              "       [417, 877, 166, 213, 517]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Testing function with the n_grams_seq of the first example\n",
        "first_padded_seq = pad_seqs(first_example_sequence, len(first_example_sequence))\n",
        "first_padded_seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re_avDznXRnU"
      },
      "source": [
        "**Expected Output:**\n",
        "\n",
        "```\n",
        "array([[  0,   0,   0,  34, 417],\n",
        "       [  0,   0,  34, 417, 877],\n",
        "       [  0,  34, 417, 877, 166],\n",
        "       [ 34, 417, 877, 166, 213],\n",
        "       [417, 877, 166, 213, 517]], dtype=int32)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j56_UCOBYzZt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e608977e-f61c-4e45-95cf-9e47d8232cbb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   8, 878],\n",
              "       [  0,   0,   0,   0,   0,   8, 878, 134],\n",
              "       [  0,   0,   0,   0,   8, 878, 134, 351],\n",
              "       [  0,   0,   0,   8, 878, 134, 351, 102],\n",
              "       [  0,   0,   8, 878, 134, 351, 102, 156],\n",
              "       [  0,   8, 878, 134, 351, 102, 156, 199],\n",
              "       [  0,   0,   0,   0,   0,   0,  16,  22],\n",
              "       [  0,   0,   0,   0,   0,  16,  22,   2],\n",
              "       [  0,   0,   0,   0,  16,  22,   2, 879],\n",
              "       [  0,   0,   0,  16,  22,   2, 879,  61],\n",
              "       [  0,   0,  16,  22,   2, 879,  61,  30],\n",
              "       [  0,  16,  22,   2, 879,  61,  30,  48],\n",
              "       [ 16,  22,   2, 879,  61,  30,  48, 634],\n",
              "       [  0,   0,   0,   0,   0,   0,  25, 311],\n",
              "       [  0,   0,   0,   0,   0,  25, 311, 635],\n",
              "       [  0,   0,   0,   0,  25, 311, 635, 102],\n",
              "       [  0,   0,   0,  25, 311, 635, 102, 200],\n",
              "       [  0,   0,  25, 311, 635, 102, 200,  25],\n",
              "       [  0,  25, 311, 635, 102, 200,  25, 278]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Testing function with the n_grams_seq of the next 3 examples\n",
        "next_3_padded_seq = pad_seqs(next_3_examples_sequence, max([len(s) for s in next_3_examples_sequence]))\n",
        "next_3_padded_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgK-Q_micEYA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a680c026-3a56-4d71-ba52-863d51ba3a3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "padded corpus has shape: (15462, 11)\n"
          ]
        }
      ],
      "source": [
        "# Pad the whole corpus\n",
        "input_sequences = pad_seqs(input_sequences, max_sequence_len)\n",
        "\n",
        "print(f\"padded corpus has shape: {input_sequences.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbOidyPrXxf7"
      },
      "source": [
        "## Split the data into features and labels\n",
        "\n",
        "Before feeding the data into the neural network we should split it into features and labels. In this case the features will be the padded n_gram sequences with the last word removed from them and the labels will be the removed word.\n",
        "\n",
        "`features_and_labels` function expects the padded n_gram sequences as input and should return a tuple containing the features and the one hot encoded labels.\n",
        "\n",
        "The function also receives the total of words in the corpus, this parameter will be very important when one hot enconding the labels since every word in the corpus will be a label at least once. If you need a refresh of how the `to_categorical` function works take a look at the [docs](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "9WGGbYdnZdmJ"
      },
      "outputs": [],
      "source": [
        "def features_and_labels(input_sequences, total_words):\n",
        "    features = input_sequences[:, :-1]\n",
        "    labels = input_sequences[:, -1]\n",
        "    one_hot_labels = to_categorical(labels, num_classes=total_words)\n",
        "    return features, one_hot_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23DolaBRaIAZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fdb7dbe-08db-4e4e-a4de-8741298d4a89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels have shape: (5, 3211)\n",
            "\n",
            "features look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,  34],\n",
              "       [  0,   0,  34, 417],\n",
              "       [  0,  34, 417, 877],\n",
              "       [ 34, 417, 877, 166],\n",
              "       [417, 877, 166, 213]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Testing function with the padded n_grams_seq of the first example\n",
        "first_features, first_labels = features_and_labels(first_padded_seq, total_words)\n",
        "\n",
        "print(f\"labels have shape: {first_labels.shape}\")\n",
        "print(\"\\nfeatures look like this:\\n\")\n",
        "first_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRTuLEt3bRKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4293523c-8392-4913-cd86-e72a673726d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features have shape: (15462, 10)\n",
            "labels have shape: (15462, 3211)\n"
          ]
        }
      ],
      "source": [
        "# Split the whole corpus\n",
        "features, labels = features_and_labels(input_sequences, total_words)\n",
        "\n",
        "print(f\"features have shape: {features.shape}\")\n",
        "print(f\"labels have shape: {labels.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltxaOCE_aU6J"
      },
      "source": [
        "## Create the model\n",
        "\n",
        "Some note to create model:\n",
        "\n",
        "- An appropriate `output_dim` for the first layer (Embedding) is 100,\n",
        "- A Bidirectional LSTM\n",
        "- The last layer should have the same number of units as the total number of words in the corpus and a softmax activation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "XrE6kpJFfvRY"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: create_model\n",
        "def create_model(total_words, max_sequence_len):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "    model.add(Bidirectional(LSTM(80)))\n",
        "    model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IpX_Gu_gISk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26cbd06a-d9a4-42d6-985d-2bbabc1a061e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "484/484 [==============================] - 10s 14ms/step - loss: 6.9223 - accuracy: 0.0209\n",
            "Epoch 2/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 6.4664 - accuracy: 0.0290\n",
            "Epoch 3/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 6.2677 - accuracy: 0.0391\n",
            "Epoch 4/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 6.0439 - accuracy: 0.0477\n",
            "Epoch 5/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 5.8041 - accuracy: 0.0559\n",
            "Epoch 6/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 5.5527 - accuracy: 0.0668\n",
            "Epoch 7/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 5.2893 - accuracy: 0.0777\n",
            "Epoch 8/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 5.0224 - accuracy: 0.0910\n",
            "Epoch 9/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 4.7616 - accuracy: 0.1066\n",
            "Epoch 10/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 4.5058 - accuracy: 0.1312\n",
            "Epoch 11/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 4.2639 - accuracy: 0.1582\n",
            "Epoch 12/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 4.0275 - accuracy: 0.1952\n",
            "Epoch 13/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 3.8036 - accuracy: 0.2293\n",
            "Epoch 14/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 3.5898 - accuracy: 0.2667\n",
            "Epoch 15/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 3.3833 - accuracy: 0.3025\n",
            "Epoch 16/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 3.1892 - accuracy: 0.3395\n",
            "Epoch 17/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 3.0113 - accuracy: 0.3729\n",
            "Epoch 18/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 2.8433 - accuracy: 0.4042\n",
            "Epoch 19/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 2.6827 - accuracy: 0.4371\n",
            "Epoch 20/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 2.5376 - accuracy: 0.4680\n",
            "Epoch 21/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 2.3951 - accuracy: 0.4965\n",
            "Epoch 22/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 2.2653 - accuracy: 0.5237\n",
            "Epoch 23/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 2.1459 - accuracy: 0.5447\n",
            "Epoch 24/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 2.0342 - accuracy: 0.5730\n",
            "Epoch 25/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 1.9227 - accuracy: 0.5976\n",
            "Epoch 26/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 1.8265 - accuracy: 0.6182\n",
            "Epoch 27/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 1.7301 - accuracy: 0.6359\n",
            "Epoch 28/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 1.6475 - accuracy: 0.6566\n",
            "Epoch 29/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 1.5635 - accuracy: 0.6711\n",
            "Epoch 30/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 1.4873 - accuracy: 0.6878\n",
            "Epoch 31/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 1.4166 - accuracy: 0.7034\n",
            "Epoch 32/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 1.3446 - accuracy: 0.7191\n",
            "Epoch 33/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 1.2827 - accuracy: 0.7323\n",
            "Epoch 34/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 1.2275 - accuracy: 0.7437\n",
            "Epoch 35/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 1.1683 - accuracy: 0.7577\n",
            "Epoch 36/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 1.1220 - accuracy: 0.7648\n",
            "Epoch 37/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 1.0800 - accuracy: 0.7746\n",
            "Epoch 38/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 1.0297 - accuracy: 0.7840\n",
            "Epoch 39/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.9943 - accuracy: 0.7896\n",
            "Epoch 40/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.9558 - accuracy: 0.7979\n",
            "Epoch 41/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.9218 - accuracy: 0.8048\n",
            "Epoch 42/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.8919 - accuracy: 0.8092\n",
            "Epoch 43/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.8629 - accuracy: 0.8135\n",
            "Epoch 44/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.8366 - accuracy: 0.8161\n",
            "Epoch 45/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.8127 - accuracy: 0.8209\n",
            "Epoch 46/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.7893 - accuracy: 0.8254\n",
            "Epoch 47/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.7706 - accuracy: 0.8288\n",
            "Epoch 48/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.7493 - accuracy: 0.8312\n",
            "Epoch 49/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.7294 - accuracy: 0.8337\n",
            "Epoch 50/50\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.7126 - accuracy: 0.8366\n"
          ]
        }
      ],
      "source": [
        "# Get the untrained model\n",
        "model = create_model(total_words, max_sequence_len)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(features, labels, epochs=50, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fXTEO3GJ282",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "1850bfd1-cea9-440b-ba54-70688247982f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Training curves of model\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QRG73l6qE-c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b6f946c9-a7d6-4072-bd91-394eac95ea5b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bbe4a942-069b-487e-ab43-18201fee0e4d\", \"history.pkl\", 944)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def download_history():\n",
        "  import pickle\n",
        "  from google.colab import files\n",
        "\n",
        "  with open('history.pkl', 'wb') as f:\n",
        "    pickle.dump(history.history, f)\n",
        "\n",
        "  files.download('history.pkl')\n",
        "\n",
        "download_history()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdsMszk9zBs_"
      },
      "source": [
        "## See model in action\n",
        "\n",
        "model generating text.\n",
        "\n",
        "Run the cell below to generate the next 100 words of a seed text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Vc6PHgxa6Hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abaaac9c-a082-4387-b55f-d4c1e6f2c9ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help me Obi Wan Kenobi, you're my only hope doth love's new clearer ' ' her in ' which it live in thy sweet hue pleasure brought ' to catch these live remember'd me still me still me bright are thine alone in her will still all these i bring lies truly promise me ' thee are a catch respect so end to stand ' prove thee bright prove me live assured her mine eyes more express'd more limbecks perfumes to ground to place me me taste do live bright is not bright in mine sweet self too lies loved ' back on thee steal imitated days lie bright\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
        "next_words = 100\n",
        "\n",
        "for _ in range(next_words):\n",
        "\t# Convert the text into sequences\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\t# Pad the sequences\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\t# Get the probabilities of predicting a word\n",
        "\tpredicted = model.predict(token_list, verbose=0)\n",
        "\t# Choose the next word based on the maximum probability\n",
        "\tpredicted = np.argmax(predicted, axis=-1).item()\n",
        "\t# Get the actual word from the word index\n",
        "\toutput_word = tokenizer.index_word[predicted]\n",
        "\t# Append to the current text\n",
        "\tseed_text += \" \" + output_word\n",
        "\n",
        "print(seed_text)"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "main_language": "python"
    },
    "accelerator": "TPU",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}